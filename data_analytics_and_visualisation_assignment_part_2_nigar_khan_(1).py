# -*- coding: utf-8 -*-
"""Data Analytics and Visualisation Assignment Part 2 - Nigar Khan (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1giI0nT7F9NWW-F30YbEwio7D3w0nS09X
"""

# Importing important libriers for data manupulation and handling.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings("ignore")

"""# Data Exploration & Data validation"""

df = pd.read_excel("Adidas US Sales Datasets.xlsx")

df.head()

df.shape

df.info()

"""- The dataset have more than 1000 records."""

for i in df.columns:
    print(i,df[i].nunique())

# Drop the 'Unnamed: 0' column
df.drop("Unnamed: 0", axis=1, inplace=True)

# Drop the first 3 rows
df = df.drop(df.index[:3])

# Set the column names from the first row
df.columns = df.iloc[0]

# Reset the index and drop the old index column
df.reset_index(drop=True, inplace=True)

# Drop the first row since it's now redundant
df = df.drop(df.index[0])

# Reset the index again after dropping the first row
df.reset_index(drop=True, inplace=True)

# Print the first 5 rows to check the changes
df.head()

df.isnull().sum()

df.info()

for i in df.columns:
    print(i,df[i].nunique())

"""### Findings
1. 7 retailers and 5 unique retailer IDs.

2. 725 unique invoice dates.

3. 6 unique regions, 51 states, and 53 cities.

4. 7 unique products sold.

5. 147 unique price points.

6. 362 unique values for units sold.

7. 3513 unique total sales amounts.

8. 6511 unique operating profit values.

9. 128 unique values for operating margin.

10. 4 different sales methods used.

These findings provide valuable insights into sales operations for various products across different retailers and regions.
"""

df['Units Sold'] = pd.to_numeric(df['Units Sold'], errors='coerce')

product_sales = df.groupby('Product')['Units Sold'].sum().sort_values(ascending=False)

product_sales

plt.figure(figsize=(10, 6))
plt.bar(product_sales.index, product_sales.values, color='skyblue')
plt.xlabel('Product')
plt.ylabel('Total Units Sold')
plt.title('Total Units Sold by Product')
plt.xticks(rotation=45)
plt.show()

product_sales.plot(kind='bar', figsize=(12, 7), title='Total Sales per Product')
plt.xticks(rotation=45)
plt.xlabel('Product')
plt.ylabel('Total Sales')
plt.show()

# Convert the 'Units Sold' column to numeric data type, handling errors by converting them to NaN
df['Units Sold'] = pd.to_numeric(df['Units Sold'], errors='coerce')

# Group the data by 'Retailer', summing the 'Units Sold' for each retailer, then sort in descending order and reset the index
total_units_sold_per_retailer = df.groupby('Retailer')['Units Sold'].sum().sort_values(ascending=False).reset_index()

# Display the total units sold for each retailer
total_units_sold_per_retailer

# Calculate the total units sold for each retailer
retailer_sales = df.groupby('Retailer')['Units Sold'].sum()

# Plot a pie chart showing the percentage of total units sold for each retailer
plt.figure(figsize=(10, 6))
plt.pie(retailer_sales, labels=retailer_sales.index, autopct='%1.1f%%')
plt.title('Percentage of Total Units Sold by Retailer')
plt.show()

# Convert 'Units Sold' column to numeric data type
df['Units Sold'] = pd.to_numeric(df['Units Sold'], errors='coerce')

# Group by 'Retailer', sum the 'Units Sold', sort in descending order
total_units_sold_per_retailer = df.groupby('Retailer')['Units Sold'].sum().sort_values(ascending=False)

# Plot a horizontal bar chart
plt.figure(figsize=(10, 6))
plt.barh(total_units_sold_per_retailer.index, total_units_sold_per_retailer.values, color='skyblue')
plt.xlabel('Total Units Sold')
plt.ylabel('Retailer')
plt.title('Total Units Sold per Retailer')
plt.show()

df.Retailer.value_counts()

df.Product.value_counts()

df["Sales Method"].value_counts()

# Filter out rows where 'Invoice Date' is not a valid date
df = df[df['Invoice Date'] != 'Invoice Date']

# Convert 'Invoice Date' column to datetime
df['Invoice Date'] = pd.to_datetime(df['Invoice Date'], format='%Y-%m-%d')

# Group by 'Invoice Date' and sum the 'Total Sales' for each date
total_sales_over_time = df.groupby('Invoice Date')['Total Sales'].sum()

# Plot a line graph of total sales over time
plt.figure(figsize=(12, 6))
plt.plot(total_sales_over_time.index, total_sales_over_time.values)
plt.xlabel('Date')
plt.ylabel('Total Sales')
plt.title('Total Sales Over Time')
plt.grid(True)
plt.show()

df.info()

plt.figure(figsize=(12, 8))
sns.set(font_scale=1.2)  # Increase font size

# Set a custom color palette
custom_palette = sns.color_palette("husl", len(df['Retailer'].unique()))
sns.set_palette(custom_palette)

# Create the countplot
sns.countplot(data=df, x="Sales Method", hue="Retailer")

plt.title('Count of Sales Method by Retailer')
plt.xlabel('Sales Method')
plt.ylabel('Count')
plt.legend(title='Retailer', loc='upper left')
plt.xticks(rotation=45)
plt.show()

pivot_df = df.pivot_table(index='Retailer', columns='Product', values='Units Sold', aggfunc='sum')

plt.figure(figsize=(12, 8))
sns.heatmap(pivot_df, cmap='viridis', annot=True, fmt=".1f", linewidths=.5)
plt.title('Heatmap of Units Sold by Retailer and Product')
plt.show()

df.info()

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.preprocessing import StandardScaler
from sklearn import tree
from sklearn.metrics import mean_squared_error, r2_score

"""# Linear Regression Model"""

X = df[['Units Sold','Operating Profit','Operating Margin','Price per Unit']] #features
y = df['Total Sales'] # target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

model = LinearRegression()
model.fit(X_train, y_train)
y_predicted_lr = model.predict(X_test)
y_predicted_lr

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, y_predicted_lr)
print("Mean Squared Error:", mse)

# Calculate R-squared
r2_lr = r2_score(y_test, y_predicted_lr)
print("R-squared Score:", r2_lr)

model.score(X_test,y_test)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_predicted_lr)
plt.xlabel('Actual Total Sales')
plt.ylabel('Predicted Total Sales')
plt.title('Actual vs. Predicted Total Sales')
plt.show()

"""# Random Forest Model"""

X = df[['Units Sold','Operating Profit','Operating Margin','Price per Unit']] #features
y = df['Total Sales'] # target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

model = RandomForestRegressor (n_estimators = 5)
model.fit(X_train, y_train)
y_predicted_rf = model.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, y_predicted_rf)
print("Mean Squared Error:", mse)

# Calculate R-squared Score
r2_rf = r2_score(y_test, y_predicted_rf)
print("R-squared Score:", r2_rf)

model.score(X_test,y_test)

# Plotting the scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_predicted_rf)
plt.xlabel('Actual Total Sales')
plt.ylabel('Predicted Total Sales')
plt.title('Actual vs. Predicted Total Sales')
plt.show()

"""# Descion Tree Model"""

model = tree.DecisionTreeRegressor()
X = df[['Units Sold','Operating Profit','Operating Margin','Price per Unit']] #features
y = df['Total Sales'] # target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

model.fit(X_train, y_train)
y_predicted_dt = model.predict(X_test)

# Calculate Mean Squared Error
mse = mean_squared_error(y_test, y_predicted_dt)
print("Mean Squared Error:", mse)

# Calculate R-squared
r2_dt = r2_score(y_test, y_predicted_dt)
print("R-squared Score:", r2_dt)

model.score(X_test,y_test)

# Plot predicted vs actual values
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_predicted_dt)
plt.xlabel("Actual Total Sales")
plt.ylabel("Predicted Total Sales")
plt.title("Decision Tree Regression: Actual vs Predicted Total Sales")
plt.show()

"""# Scalling Data For Randon Forest Model"""

X = df[['Units Sold','Operating Profit','Operating Margin','Price per Unit']] #features
y = df['Total Sales'] # target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
model = RandomForestRegressor(n_estimators = 9)
model.fit(X_train, y_train)
y_predicted_rf = model.predict(X_test)

model.score(X_test,y_test)

"""# K Neighbors Model"""

X = df[['Units Sold','Operating Profit','Operating Margin','Price per Unit']] #features
y = df['Total Sales'] # target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

from sklearn.model_selection import learning_curve

# Initialize the KNeighborsRegressor model
model = KNeighborsRegressor(n_neighbors=5)

# Calculate the learning curve
train_sizes, train_scores, test_scores = learning_curve(
    model, X_train, y_train, cv=5, scoring='neg_mean_squared_error', n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

train_scores_mean = -np.mean(train_scores, axis=1)
test_scores_mean = -np.mean(test_scores, axis=1)

for i, train_score, test_score in zip(train_sizes, train_scores_mean, test_scores_mean):
    print(f"Training Size: {i}, Train Score: {train_score}, Test Score: {test_score}")

# Plot the learning curve
plt.figure()
plt.title("KNeighborsRegressor Learning Curve")
plt.xlabel("Training Examples")
plt.ylabel("Negative Mean Squared Error")
plt.grid()

plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training Score")
plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Cross-validation Score")

plt.legend(loc="best")
plt.show()

from sklearn.metrics import mean_squared_error, r2_score

# Calculate Mean Squared Error and R-squared for Linear Regression
mse_lr = mean_squared_error(y_test, y_predicted_lr)
r2_lr = r2_score(y_test, y_predicted_lr)

# Calculate Mean Squared Error and R-squared for Random Forest
mse_rf = mean_squared_error(y_test, y_predicted_rf)
r2_rf = r2_score(y_test, y_predicted_rf)

# Calculate Mean Squared Error and R-squared for Decision Tree
mse_dt = mean_squared_error(y_test, y_predicted_dt)
r2_dt = r2_score(y_test, y_predicted_dt)

print("Linear Regression - Mean Squared Error:", mse_lr)
print("Linear Regression - R-squared:", r2_lr)
print("Random Forest - Mean Squared Error:", mse_rf)
print("Random Forest - R-squared:", r2_rf)
print("Decision Tree - Mean Squared Error:", mse_dt)
print("Decision Tree - R-squared:", r2_dt)

import matplotlib.pyplot as plt

# Model names
models = ['Linear Regression', 'Random Forest', 'Decision Tree']

# MSE values
mse_values = [mse_lr, mse_rf, mse_dt]

# R-squared values
r2_values = [r2_lr, r2_rf, r2_dt]

# Plotting
fig, ax = plt.subplots(1, 2, figsize=(12, 6))

# Bar plot for MSE
ax[0].bar(models, mse_values, color='skyblue')
ax[0].set_title('Mean Squared Error')
ax[0].set_xlabel('Models')
ax[0].set_ylabel('MSE')

# Bar plot for R-squared
ax[1].bar(models, r2_values, color='salmon')
ax[1].set_title('R-squared')
ax[1].set_xlabel('Models')
ax[1].set_ylabel('R-squared')

plt.tight_layout()
plt.show()

# Define the models
models = [
    ("Linear Regression", LinearRegression()),
    ("Random Forest", RandomForestRegressor(n_estimators=100)),
    ("Decision Tree", DecisionTreeRegressor()),
    ("K Neighbors", KNeighborsRegressor(n_neighbors=5))
]

# Plot the learning curves for each model
plt.figure(figsize=(12, 8))
for name, model in models:
    train_sizes, train_scores, test_scores = learning_curve(
        model, X_train, y_train, cv=5, scoring='neg_mean_squared_error',
        train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=-1
    )
    train_scores_mean = -np.mean(train_scores, axis=1)
    test_scores_mean = -np.mean(test_scores, axis=1)

    plt.plot(train_sizes, train_scores_mean, label=f"{name} Training Score")
    plt.plot(train_sizes, test_scores_mean, label=f"{name} Cross-validation Score")

plt.xlabel("Training Examples")
plt.ylabel("Negative Mean Squared Error")
plt.title("Comparison of Learning Curves for Different Models")
plt.legend()
plt.show()